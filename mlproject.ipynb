{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mlproject.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "8M_LMWkrhbt-",
        "S8u_oHqgIoh0",
        "CE5ARhXzI_Di",
        "fR4JdAYjmwnR"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#data set link :https://drive.google.com/drive/folders/1X7FGBuxx2405tv64OnxebB3fLq--5Ada?usp=sharing"
      ],
      "metadata": {
        "id": "tyvL57EGWfOK"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8M_LMWkrhbt-"
      },
      "source": [
        "#Matrix factorization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QU6UXBrM0dDQ"
      },
      "source": [
        "#library imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from sklearn.model_selection import train_test_split\n",
        "from scipy import sparse\n",
        "#import jovian"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Dt97Bzu2F-c",
        "outputId": "9ff1ec5c-cc1b-43aa-98e3-aef80836d5a3"
      },
      "source": [
        "movie_ratings_df = pd.read_csv(\"/content/ratings.csv\")\n",
        "movie_ratings_df.shape\n",
        "print(movie_ratings_df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   userId  movieId  rating\n",
            "0       1        1     4.0\n",
            "1       1        3     4.0\n",
            "2       1        6     4.0\n",
            "3       1       47     5.0\n",
            "4       1       50     5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRoAaKlC3Dtk",
        "outputId": "34dd6fa6-5a2e-47b4-e05f-201ee4b803a0"
      },
      "source": [
        "#checking for null values\n",
        "movie_ratings_df.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "userId     0\n",
              "movieId    0\n",
              "rating     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaOaC1Ug3hva",
        "outputId": "1e61a535-89ee-4883-d264-825fccaf9e7b"
      },
      "source": [
        "#calculating number of each rating\n",
        "Counter(movie_ratings_df.rating)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({0.5: 1370,\n",
              "         1.0: 2811,\n",
              "         1.5: 1791,\n",
              "         2.0: 7551,\n",
              "         2.5: 5550,\n",
              "         3.0: 20047,\n",
              "         3.5: 13136,\n",
              "         4.0: 26818,\n",
              "         4.5: 8551,\n",
              "         5.0: 13211})"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUJcdQef3ysA",
        "outputId": "1ad4e7dc-c9c2-4a50-8607-4c7d0681d44e"
      },
      "source": [
        "#distribution of userid with movies\n",
        "movie_ratings_df.groupby(['userId']).count()['movieId']\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "userId\n",
              "1       232\n",
              "2        29\n",
              "3        39\n",
              "4       216\n",
              "5        44\n",
              "       ... \n",
              "606    1115\n",
              "607     187\n",
              "608     831\n",
              "609      37\n",
              "610    1302\n",
              "Name: movieId, Length: 610, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvbkZLnx_xp-",
        "outputId": "29124bfa-ca73-4b31-ad09-9f01a7d2d44f"
      },
      "source": [
        "#Average number of ratings per user\n",
        "np.mean(movie_ratings_df.groupby(['userId']).count()['movieId'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "165.30491803278687"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieoiNbCf__kn"
      },
      "source": [
        "train_df, valid_df = train_test_split(movie_ratings_df, test_size=0.2)\n",
        "\n",
        "#resetting indices to avoid indexing errors in the future\n",
        "train_df = train_df.reset_index()[['userId', 'movieId', 'rating']]\n",
        "valid_df = valid_df.reset_index()[['userId', 'movieId', 'rating']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4t1p-O6bPk_Q"
      },
      "source": [
        "userId = np.array(movie_ratings_df['userId'])\n",
        "movieId = np.array(movie_ratings_df['movieId'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8u_oHqgIoh0"
      },
      "source": [
        "#Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rr99P4f7BLfb"
      },
      "source": [
        "we need continuous IDs to be able to index into the embedding matrix and access each user/item embedding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAMuNsXOAypw"
      },
      "source": [
        "def encode_column(column):\n",
        "    \"\"\" Encodes a pandas column with continous IDs\"\"\"\n",
        "    keys = column.unique()\n",
        "    key_to_id = {key:idx for idx,key in enumerate(keys)}\n",
        "    return key_to_id, np.array([key_to_id[x] for x in column]), len(keys)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ex-MxS0A1Bs"
      },
      "source": [
        "def encode_df(movie_df):\n",
        "    \"\"\"Encodes rating data with continuous user and movie ids\"\"\"\n",
        "    \n",
        "    movieIds, movie_df['movieId'], num_movie = encode_column(movie_df['movieId'])\n",
        "    userIds, movie_df['userId'], num_users = encode_column(movie_df['userId'])\n",
        "    return movie_df, num_users, num_movie, userIds, movieIds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "B-AqEwEfA3fm",
        "outputId": "84aefbc3-2bb9-4066-e5d8-3d8e1b868e02"
      },
      "source": [
        "movie_df, num_users, num_movie, userIds, movieIds = encode_df(train_df)\n",
        "print(\"Number of users :\", num_users)\n",
        "print(\"Number of movie :\", num_movie)\n",
        "movie_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of users : 610\n",
            "Number of movie : 8998\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3.5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userId  movieId  rating\n",
              "0       0        0     5.0\n",
              "1       1        1     3.0\n",
              "2       2        2     3.0\n",
              "3       3        3     3.5\n",
              "4       4        4     2.0"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CE5ARhXzI_Di"
      },
      "source": [
        "#Training\n",
        "Our goal is to find the optimal embeddings for each user and each item."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVPQyr0-Bm4R"
      },
      "source": [
        "Initializing user and item embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlWJdgefBqUj"
      },
      "source": [
        "def create_embeddings(n, K):\n",
        "    \"\"\"\n",
        "    Creates a random numpy matrix of shape n, K with uniform values in (0, 11/K)\n",
        "    n: number of items/users\n",
        "    K: number of factors in the embedding \n",
        "    \"\"\"\n",
        "    return 11*np.random.random((n, K)) / K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UfXKTz3B2rp"
      },
      "source": [
        "Creating Sparse utility matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPwAnvduBtp6"
      },
      "source": [
        "def create_sparse_matrix(df, rows, cols, column_name=\"rating\"):\n",
        "  return sparse.csc_matrix((df[column_name].values,(df['userId'].values, df['movieId'].values)),shape=(rows, cols))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9SD9w_cB5au",
        "outputId": "4176c6a3-f6bd-4e10-e384-8e32fb9b8646"
      },
      "source": [
        "movie_df, num_users, num_movie, userIds, movieIds = encode_df(train_df)\n",
        "Y = create_sparse_matrix(movie_df, num_users, num_movie)\n",
        "# to view matrix\n",
        "Y.todense()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "matrix([[5., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 3., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 3., ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.],\n",
              "        [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zia7BsL5Ddku"
      },
      "source": [
        "Making predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wptOMrYaCP7l"
      },
      "source": [
        "def predict(df, emb_user, emb_movie):\n",
        "    \"\"\" This function computes df[\"prediction\"] without doing (U*V^T).\n",
        "    \n",
        "    Computes df[\"prediction\"] by using elementwise multiplication of the corresponding embeddings and then \n",
        "    sum to get the prediction u_i*v_j. This avoids creating the dense matrix U*V^T.\n",
        "    \"\"\"\n",
        "    df['prediction'] = np.sum(np.multiply(emb_movie[df['movieId']],emb_user[df['userId']]), axis=1)\n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVMvo0OEIVbo"
      },
      "source": [
        "Cost function: We are trying to minimize the Mean squared error over the utility matrix. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66Yki2uKDfXG"
      },
      "source": [
        "lmbda = 0.0001"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThxzPk7UDffN"
      },
      "source": [
        "def cost(df, emb_user, emb_movie):\n",
        "    \"\"\" Computes mean square error\"\"\"\n",
        "    Y = create_sparse_matrix(df, emb_user.shape[0], emb_movie.shape[0])\n",
        "    predicted = create_sparse_matrix(predict(df, emb_user, emb_movie), emb_user.shape[0], emb_movie.shape[0], 'prediction')\n",
        "    return np.sum((Y-predicted).power(2))/df.shape[0] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVM6CjnQDqDn"
      },
      "source": [
        "Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6W7lqNPdDfiK"
      },
      "source": [
        "def gradient(df, emb_user, emb_movie):\n",
        "    \"\"\" Computes the gradient for user and movie embeddings\"\"\"\n",
        "    Y = create_sparse_matrix(df, emb_user.shape[0], emb_movie.shape[0])\n",
        "    predicted = create_sparse_matrix(predict(df, emb_user, emb_movie), emb_user.shape[0], emb_movie.shape[0], 'prediction')\n",
        "    delta =(Y-predicted)\n",
        "    grad_user = (-2/df.shape[0])*(delta*emb_movie) + 2*lmbda*emb_user\n",
        "    grad_movie = (-2/df.shape[0])*(delta.T*emb_user) + 2*lmbda*emb_movie\n",
        "    return grad_user, grad_movie"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35yA2TQMDqt4"
      },
      "source": [
        "def gradient_descent(df, emb_user, emb_movie, iterations=2000, learning_rate=0.001, df_val=None):\n",
        "    \"\"\" \n",
        "    Computes gradient descent with momentum (0.9) for given number of iterations.\n",
        "    emb_user: the trained user embedding\n",
        "    emb_movie: the trained movie embedding\n",
        "    \"\"\"\n",
        "    Y = create_sparse_matrix(df, emb_user.shape[0], emb_movie.shape[0])\n",
        "    beta = 0.9\n",
        "    grad_user, grad_movie = gradient(df, emb_user, emb_movie)\n",
        "    v_user = grad_user\n",
        "    v_movie = grad_movie\n",
        "    for i in range(iterations):\n",
        "        grad_user, grad_movie = gradient(df, emb_user, emb_movie)\n",
        "        v_user = beta*v_user + (1-beta)*grad_user\n",
        "        v_movie = beta*v_movie + (1-beta)*grad_movie\n",
        "        emb_user = emb_user - learning_rate*v_user\n",
        "        emb_movie = emb_movie - learning_rate*v_movie\n",
        "        if(not (i+1)%50):\n",
        "            print(\"\\niteration\", i+1, \":\")\n",
        "            print(\"train mse:\",  cost(df, emb_user, emb_movie))\n",
        "            if df_val is not None:\n",
        "                print(\"validation mse:\",  cost(df_val, emb_user, emb_movie))\n",
        "    return emb_user, emb_movie"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OhICHIDDuZg",
        "outputId": "53b9ed7c-aa41-4f61-e3ff-064cff78b1bf"
      },
      "source": [
        "emb_user = create_embeddings(num_users, 3)\n",
        "emb_movie = create_embeddings(num_movie, 3)\n",
        "emb_user, emb_movie = gradient_descent(movie_df, emb_user, emb_movie, iterations=800, learning_rate=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "iteration 50 :\n",
            "train mse: 5.022269806729269\n",
            "\n",
            "iteration 100 :\n",
            "train mse: 3.255948600694187\n",
            "\n",
            "iteration 150 :\n",
            "train mse: 2.615870198067016\n",
            "\n",
            "iteration 200 :\n",
            "train mse: 2.2467773069258974\n",
            "\n",
            "iteration 250 :\n",
            "train mse: 2.0020542811584296\n",
            "\n",
            "iteration 300 :\n",
            "train mse: 1.82588411668126\n",
            "\n",
            "iteration 350 :\n",
            "train mse: 1.6919939427577781\n",
            "\n",
            "iteration 400 :\n",
            "train mse: 1.5863039913726842\n",
            "\n",
            "iteration 450 :\n",
            "train mse: 1.500527734782006\n",
            "\n",
            "iteration 500 :\n",
            "train mse: 1.4294218896512407\n",
            "\n",
            "iteration 550 :\n",
            "train mse: 1.369473475233894\n",
            "\n",
            "iteration 600 :\n",
            "train mse: 1.3182204079710418\n",
            "\n",
            "iteration 650 :\n",
            "train mse: 1.2738754760541238\n",
            "\n",
            "iteration 700 :\n",
            "train mse: 1.2351055061819118\n",
            "\n",
            "iteration 750 :\n",
            "train mse: 1.200894601121114\n",
            "\n",
            "iteration 800 :\n",
            "train mse: 1.1704553861084963\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CLxmuQ4EOAM"
      },
      "source": [
        "Making predictions on new data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFKAvkfpEHYm"
      },
      "source": [
        "def encode_new_data(valid_df, userIds, movieIds):\n",
        "    \"\"\" Encodes valid_df with the same encoding as train_df.\n",
        "    \"\"\"\n",
        "    df_val_chosen = valid_df['movieId'].isin(movieIds.keys()) & valid_df['userId'].isin(userIds.keys())\n",
        "    valid_df = valid_df[df_val_chosen]\n",
        "    valid_df['movieId'] =  np.array([movieIds[x] for x in valid_df['movieId']])\n",
        "    valid_df['userId'] = np.array([userIds[x] for x in valid_df['userId']])\n",
        "    return valid_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__DcES6xEd7P",
        "outputId": "0fa02df5-29a9-4d5d-b7cd-b1250c9ed7af"
      },
      "source": [
        "print(\"before encoding:\", valid_df.shape)\n",
        "valid_df = encode_new_data(valid_df, userIds, movieIds)\n",
        "print(\"after encoding:\", valid_df.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "before encoding: (20168, 3)\n",
            "after encoding: (15501, 3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_q_A2nrEEgBC",
        "outputId": "925efdc5-088d-456e-98af-6600aa0ce316"
      },
      "source": [
        "train_mse = cost(train_df, emb_user, emb_movie)\n",
        "val_mse = cost(valid_df, emb_user, emb_movie)\n",
        "print(train_mse, val_mse)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.1704553861084963 2.674848826083774\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "l0KNmIGWEh3C",
        "outputId": "efd6d9ef-ef84-49af-95a5-d9c4eb3fb5ed"
      },
      "source": [
        "#looking at the predictions\n",
        "valid_df[1:10].head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>74</td>\n",
              "      <td>6787</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.980296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>474</td>\n",
              "      <td>41</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.631385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>240</td>\n",
              "      <td>519</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.489681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>600</td>\n",
              "      <td>4975</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.579600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>249</td>\n",
              "      <td>2231</td>\n",
              "      <td>3.5</td>\n",
              "      <td>3.746887</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   userId  movieId  rating  prediction\n",
              "2      74     6787     5.0    3.980296\n",
              "5     474       41     3.5    2.631385\n",
              "6     240      519     3.0    2.489681\n",
              "8     600     4975     3.5    2.579600\n",
              "9     249     2231     3.5    3.746887"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78NPG1DKQfpF"
      },
      "source": [
        "  predicted_ratings = np.array(valid_df[['prediction']])\n",
        "  true_ratings = np.array(valid_df[['rating']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "L9t4SfHrPRW1",
        "outputId": "69ddd027-54b1-4d93-83b9-f4a0fdde5b13"
      },
      "source": [
        "# importing the required module\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(movieId[:500],true_ratings[:500],label= \"stars\", color= \"blue\", marker= \"*\")\n",
        "plt.scatter(movieId[:500],predicted_ratings[:500],label= \"stars\", color= \"orange\", marker= \"*\")\n",
        "plt.title('Predicted vs Actual w.r.t MovieID')\n",
        "plt.ylabel('ratings')\n",
        "plt.xlabel('movieId')\n",
        "plt.legend(['actual', 'predicted'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "gsEg2kOPRM5f",
        "outputId": "4ebf9cc0-3ece-4dfa-dc6d-261c82acf76e"
      },
      "source": [
        "plt.scatter(userId[:500],true_ratings[:500],label= \"stars\", color= \"blue\", marker= \"*\")\n",
        "plt.scatter(userId[:500],predicted_ratings[:500],label= \"stars\", color= \"orange\", marker= \"*\")\n",
        "plt.title('Predicted vs Actual w.r.t UserID')\n",
        "plt.ylabel('ratings')\n",
        "plt.xlabel('userId')\n",
        "plt.legend(['actual', 'predicted'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEaMw3e_qWWC",
        "outputId": "57b9c8f2-7879-4c67-9847-c152dba0a10c"
      },
      "source": [
        "#evaluates on test set\n",
        "from sklearn.metrics import mean_squared_error\n",
        "def score_on_test_set():\n",
        "#user_movie_pairs = zip(valid_df[‘movieId’], valid_df[‘userId’])\n",
        "  predicted_ratings = np.array(valid_df[['prediction']])\n",
        "  true_ratings = np.array(valid_df[['rating']])\n",
        "  score = np.sqrt(mean_squared_error(true_ratings, predicted_ratings))\n",
        "  return score\n",
        "test_set_score = score_on_test_set()\n",
        "print(test_set_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.635496507511946\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWNCnaDDZquD"
      },
      "source": [
        " Common latent fac\u0002tor techniques compute a low-rank rating matrix by apply\u0002ing Singular Value Decomposition through gradient descent\n",
        "or Regularized Alternating Least Square algorithm"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0R_dVs-gn2Jn",
        "outputId": "7b6a9b15-4e23-4e3c-c730-8b9f5ec09d96"
      },
      "source": [
        "!wget http://files.grouplens.org/datasets/movielens/ml-1m.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-02 09:01:11--  http://files.grouplens.org/datasets/movielens/ml-1m.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5917549 (5.6M) [application/zip]\n",
            "Saving to: ‘ml-1m.zip.1’\n",
            "\n",
            "\rml-1m.zip.1           0%[                    ]       0  --.-KB/s               \rml-1m.zip.1          98%[==================> ]   5.54M  27.7MB/s               \rml-1m.zip.1         100%[===================>]   5.64M  27.6MB/s    in 0.2s    \n",
            "\n",
            "2021-12-02 09:01:12 (27.6 MB/s) - ‘ml-1m.zip.1’ saved [5917549/5917549]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d7nncsPwoqX9",
        "outputId": "06689f80-9d52-41ca-ee87-60484e2f78e4"
      },
      "source": [
        "!wget http://files.grouplens.org/datasets/movielens/ml-100k.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-02 08:58:42--  http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
            "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
            "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4924029 (4.7M) [application/zip]\n",
            "Saving to: ‘ml-100k.zip’\n",
            "\n",
            "ml-100k.zip         100%[===================>]   4.70M  22.3MB/s    in 0.2s    \n",
            "\n",
            "2021-12-02 08:58:42 (22.3 MB/s) - ‘ml-100k.zip’ saved [4924029/4924029]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ukuyxA4odjV",
        "outputId": "01987cf9-ef85-489d-a21e-f0ac2d2f0e39"
      },
      "source": [
        "!unzip ml-1m.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ml-1m.zip\n",
            "   creating: ml-1m/\n",
            "  inflating: ml-1m/movies.dat        \n",
            "  inflating: ml-1m/ratings.dat       \n",
            "  inflating: ml-1m/README            \n",
            "  inflating: ml-1m/users.dat         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDcwbhWDotvd",
        "outputId": "86686a0b-9fb2-4f1e-a4e2-ef0afd55d885"
      },
      "source": [
        "!unzip ml-100k.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  ml-100k.zip\n",
            "   creating: ml-100k/\n",
            "  inflating: ml-100k/allbut.pl       \n",
            "  inflating: ml-100k/mku.sh          \n",
            "  inflating: ml-100k/README          \n",
            "  inflating: ml-100k/u.data          \n",
            "  inflating: ml-100k/u.genre         \n",
            "  inflating: ml-100k/u.info          \n",
            "  inflating: ml-100k/u.item          \n",
            "  inflating: ml-100k/u.occupation    \n",
            "  inflating: ml-100k/u.user          \n",
            "  inflating: ml-100k/u1.base         \n",
            "  inflating: ml-100k/u1.test         \n",
            "  inflating: ml-100k/u2.base         \n",
            "  inflating: ml-100k/u2.test         \n",
            "  inflating: ml-100k/u3.base         \n",
            "  inflating: ml-100k/u3.test         \n",
            "  inflating: ml-100k/u4.base         \n",
            "  inflating: ml-100k/u4.test         \n",
            "  inflating: ml-100k/u5.base         \n",
            "  inflating: ml-100k/u5.test         \n",
            "  inflating: ml-100k/ua.base         \n",
            "  inflating: ml-100k/ua.test         \n",
            "  inflating: ml-100k/ub.base         \n",
            "  inflating: ml-100k/ub.test         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fR4JdAYjmwnR"
      },
      "source": [
        "#User-Based Collaborative Filtering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f3X6bYgpm1jJ"
      },
      "source": [
        "import numpy as np\n",
        "from scipy.sparse import csr_matrix\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "L8GJf11Km6zx",
        "outputId": "27fda991-5bbf-4bf3-848f-182e48988cd0"
      },
      "source": [
        "dataset = pd.read_csv('ml-100k/u.data', delimiter = '\\t',names=['user_id','item_id','rating','timestamp'])\n",
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>196</td>\n",
              "      <td>242</td>\n",
              "      <td>3</td>\n",
              "      <td>881250949</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>186</td>\n",
              "      <td>302</td>\n",
              "      <td>3</td>\n",
              "      <td>891717742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>22</td>\n",
              "      <td>377</td>\n",
              "      <td>1</td>\n",
              "      <td>878887116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>244</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>880606923</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>166</td>\n",
              "      <td>346</td>\n",
              "      <td>1</td>\n",
              "      <td>886397596</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   user_id  item_id  rating  timestamp\n",
              "0      196      242       3  881250949\n",
              "1      186      302       3  891717742\n",
              "2       22      377       1  878887116\n",
              "3      244       51       2  880606923\n",
              "4      166      346       1  886397596"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a5t0GfUHnGV8"
      },
      "source": [
        "Transforming data into the matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UA-sZN-cm-tW",
        "outputId": "f2537787-a6c8-4387-8fc0-dd56b83cbfb3"
      },
      "source": [
        "n_users = dataset.user_id.unique().shape[0]\n",
        "n_items = dataset.item_id.unique().shape[0]\n",
        "n_items = dataset['item_id'].max()\n",
        "A = np.zeros((n_users,n_items))\n",
        "for line in dataset.itertuples():\n",
        "    A[line[1]-1,line[2]-1] = line[3]\n",
        "print(\"Original rating matrix : \",A)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original rating matrix :  [[5. 3. 4. ... 0. 0. 0.]\n",
            " [4. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [5. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 5. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0Wr6A6MnP9K"
      },
      "source": [
        "converts the MovieLens dataset into the binary MovieLens dataset. We have considered items whose ratings are greater or equal to 3 being liked by the user and others being disliked by the user."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHMG_x3snHrK"
      },
      "source": [
        "for i in range(len(A)):\n",
        "  for j in range(len(A[0])):\n",
        "    if A[i][j]>=3:\n",
        "      A[i][j]=1\n",
        "    else:\n",
        "      A[i][j]=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ykRz8GjnYgj"
      },
      "source": [
        "we convert the dense rating matrix into a sparse matrix using the csr_matrix() function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cx-1eUH4nSoM",
        "outputId": "712f6079-2f90-4041-dec0-b8ba394f69a8"
      },
      "source": [
        "csr_sample = csr_matrix(A)\n",
        "print(csr_sample)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  (0, 0)\t1.0\n",
            "  (0, 1)\t1.0\n",
            "  (0, 2)\t1.0\n",
            "  (0, 3)\t1.0\n",
            "  (0, 4)\t1.0\n",
            "  (0, 5)\t1.0\n",
            "  (0, 6)\t1.0\n",
            "  (0, 8)\t1.0\n",
            "  (0, 9)\t1.0\n",
            "  (0, 11)\t1.0\n",
            "  (0, 12)\t1.0\n",
            "  (0, 13)\t1.0\n",
            "  (0, 14)\t1.0\n",
            "  (0, 15)\t1.0\n",
            "  (0, 16)\t1.0\n",
            "  (0, 17)\t1.0\n",
            "  (0, 18)\t1.0\n",
            "  (0, 19)\t1.0\n",
            "  (0, 21)\t1.0\n",
            "  (0, 22)\t1.0\n",
            "  (0, 23)\t1.0\n",
            "  (0, 24)\t1.0\n",
            "  (0, 25)\t1.0\n",
            "  (0, 27)\t1.0\n",
            "  (0, 29)\t1.0\n",
            "  :\t:\n",
            "  (942, 624)\t1.0\n",
            "  (942, 654)\t1.0\n",
            "  (942, 671)\t1.0\n",
            "  (942, 684)\t1.0\n",
            "  (942, 716)\t1.0\n",
            "  (942, 720)\t1.0\n",
            "  (942, 721)\t1.0\n",
            "  (942, 731)\t1.0\n",
            "  (942, 738)\t1.0\n",
            "  (942, 762)\t1.0\n",
            "  (942, 764)\t1.0\n",
            "  (942, 793)\t1.0\n",
            "  (942, 795)\t1.0\n",
            "  (942, 807)\t1.0\n",
            "  (942, 815)\t1.0\n",
            "  (942, 823)\t1.0\n",
            "  (942, 824)\t1.0\n",
            "  (942, 839)\t1.0\n",
            "  (942, 927)\t1.0\n",
            "  (942, 942)\t1.0\n",
            "  (942, 1043)\t1.0\n",
            "  (942, 1073)\t1.0\n",
            "  (942, 1187)\t1.0\n",
            "  (942, 1227)\t1.0\n",
            "  (942, 1329)\t1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5ImJiu-ng9v"
      },
      "source": [
        "Compute similarity between items of csr_sample using cosine similarity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNTEKx26naNj",
        "outputId": "97352f4b-b3e9-496b-912f-14df829963bf"
      },
      "source": [
        "knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=3, n_jobs=-1)\n",
        "knn.fit(csr_sample)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NearestNeighbors(algorithm='brute', metric='cosine', n_jobs=-1, n_neighbors=3)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOZFPeE9nr-g"
      },
      "source": [
        "generate recommendations for user_id:1 based on 20 items being liked by him"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKZBcuIBnjxV",
        "outputId": "d7255668-37f1-417f-a805-d8a0072e6d03"
      },
      "source": [
        "dataset_sort_des = dataset.sort_values(['user_id', 'timestamp'], ascending=[True, False])\n",
        "filter1 = dataset_sort_des[dataset_sort_des['user_id'] == 1].item_id\n",
        "filter1 = filter1.tolist()\n",
        "filter1 = filter1[:20]\n",
        "print(\"Items liked by user: \",filter1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Items liked by user:  [74, 102, 256, 5, 171, 111, 242, 189, 32, 209, 270, 18, 6, 244, 221, 129, 20, 271, 272, 255]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgjGVZcHnybi"
      },
      "source": [
        "Next, for each item being liked by the user1, we recommend 2 similar items"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyZKmy9InyKP",
        "outputId": "bbdf3500-cd82-4629-ccb4-d631ec04c590"
      },
      "source": [
        "distances1=[]\n",
        "indices1=[]\n",
        "for i in filter1:\n",
        "  distances , indices = knn.kneighbors(csr_sample[i],n_neighbors=3)\n",
        "  indices = indices.flatten()\n",
        "  indices= indices[1:]\n",
        "  indices1.extend(indices)\n",
        "print(\"Items to be recommended: \",indices1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Items to be recommended:  [356, 500, 758, 512, 883, 893, 473, 17, 311, 566, 771, 283, 614, 105, 904, 163, 510, 501, 642, 406, 473, 17, 578, 475, 312, 845, 688, 778, 681, 550, 275, 879, 365, 371, 685, 928, 719, 283, 373, 331]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KPkYV3dog7J"
      },
      "source": [
        "This is to create a repos for movie rating prediction. It covers 3 use cases.\n",
        "\n",
        "Predict user rating from 0 to 5 by creating a stacked auto-encoder netowrk.\n",
        "\n",
        "Predict user likes or not by creating a restricted Boltzmann machine.\n",
        "\n",
        "use Pearson correlation matrix and create an item-based movie recommender."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4HopnCZColXI"
      },
      "source": [
        "#Stacked_Autoencoder_Rating_Prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBJu0IolnPWb"
      },
      "source": [
        "# AutoEncoders\n",
        "\n",
        "# Importing the libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "from torch.autograd import Variable\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9RbG4AImPK0"
      },
      "source": [
        "# Importing the dataset\n",
        "movies = pd.read_csv('ml-1m/movies.dat', sep = '::', names=['title','genres'], engine = 'python', encoding = 'latin-1')\n",
        "users = pd.read_csv('ml-1m/users.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
        "ratings = pd.read_csv('ml-1m/ratings.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "NqjKMdwrm48V",
        "outputId": "d26414b0-9258-46d6-a929-93e915113174"
      },
      "source": [
        "movies.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>genres</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Toy Story (1995)</td>\n",
              "      <td>Animation|Children's|Comedy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Jumanji (1995)</td>\n",
              "      <td>Adventure|Children's|Fantasy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Grumpier Old Men (1995)</td>\n",
              "      <td>Comedy|Romance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Waiting to Exhale (1995)</td>\n",
              "      <td>Comedy|Drama</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Father of the Bride Part II (1995)</td>\n",
              "      <td>Comedy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                title                        genres\n",
              "1                    Toy Story (1995)   Animation|Children's|Comedy\n",
              "2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
              "3             Grumpier Old Men (1995)                Comedy|Romance\n",
              "4            Waiting to Exhale (1995)                  Comedy|Drama\n",
              "5  Father of the Bride Part II (1995)                        Comedy"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "5WovWQB4m7RX",
        "outputId": "2f3717c2-3be5-4b81-d089-ebd25955da3a"
      },
      "source": [
        "users.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>F</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>48067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>M</td>\n",
              "      <td>56</td>\n",
              "      <td>16</td>\n",
              "      <td>70072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>M</td>\n",
              "      <td>25</td>\n",
              "      <td>15</td>\n",
              "      <td>55117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>M</td>\n",
              "      <td>45</td>\n",
              "      <td>7</td>\n",
              "      <td>02460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>M</td>\n",
              "      <td>25</td>\n",
              "      <td>20</td>\n",
              "      <td>55455</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0  1   2   3      4\n",
              "0  1  F   1  10  48067\n",
              "1  2  M  56  16  70072\n",
              "2  3  M  25  15  55117\n",
              "3  4  M  45   7  02460\n",
              "4  5  M  25  20  55455"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kfVGquTEm9Yr",
        "outputId": "b06ad1f3-3376-43c6-af80-6905f7a27679"
      },
      "source": [
        "ratings.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1193</td>\n",
              "      <td>5</td>\n",
              "      <td>978300760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>661</td>\n",
              "      <td>3</td>\n",
              "      <td>978302109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>914</td>\n",
              "      <td>3</td>\n",
              "      <td>978301968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>3408</td>\n",
              "      <td>4</td>\n",
              "      <td>978300275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>2355</td>\n",
              "      <td>5</td>\n",
              "      <td>978824291</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0     1  2          3\n",
              "0  1  1193  5  978300760\n",
              "1  1   661  3  978302109\n",
              "2  1   914  3  978301968\n",
              "3  1  3408  4  978300275\n",
              "4  1  2355  5  978824291"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOVtreGsnKY3",
        "outputId": "35429bcf-456e-4a19-d019-105c8c483114"
      },
      "source": [
        "##create training and test set data\n",
        "# here only take u1.base but there are another u2 u3 u4 u5 base files\n",
        "training_set = pd.read_csv('ml-100k/u1.base', delimiter = '\\t', header = None)\n",
        "print(training_set.head(3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   0  1  2          3\n",
            "0  1  1  5  874965758\n",
            "1  1  2  3  876893171\n",
            "2  1  3  4  878542960\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CLqdOb41fh2c"
      },
      "source": [
        "we convert Dataframe to Numpy array because we will use Pytorch tensor which requires array as input. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeAHptV9nN5f"
      },
      "source": [
        "##convert it to array\n",
        "training_set = np.array(training_set, dtype = 'int')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8xKS-PGnPD8",
        "outputId": "c530e012-994a-4c0d-f06f-b75e463b071f"
      },
      "source": [
        "training_set.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80000, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ekXRamPHnTEM",
        "outputId": "e50db099-2a19-41d3-e266-575e2cf21cec"
      },
      "source": [
        "test_set = pd.read_csv('ml-100k/u1.test', delimiter = '\\t', header = None)\n",
        "##convert it to array\n",
        "test_set = np.array(test_set, dtype = 'int')\n",
        "test_set.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2hQbVDMnYe1"
      },
      "source": [
        "Data structure creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eO0oF7rtfscm"
      },
      "source": [
        "To prepare the training/test data, we need to create training/test sets in array format with each row representing a user and each cell in the row representing the rating for each movie. This is the expected input for auto-encoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHbA5qTtnTGE",
        "outputId": "64f30ab1-efb9-477e-f010-aac7bcf1b8a9"
      },
      "source": [
        "#take max users id in train and test data\n",
        "nb_users = int(max(max(training_set[:,0]), max(test_set[:,0])))\n",
        "nb_movies = int(max(max(training_set[:,1]), max(test_set[:,1])))\n",
        "print('Num of users: ', nb_users, '\\nNum of movies: ', nb_movies)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num of users:  943 \n",
            "Num of movies:  1682\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MmPv1sff3uN"
      },
      "source": [
        "We create a function for data conversion which returns a list of lists. Each child list represents one user’s ratings for all movies. If the user did not rate a movie, initialize the rating with 0. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oN37Gm9QnTJe"
      },
      "source": [
        "def convert(data):\n",
        "    new_data = []\n",
        "    for id_users in range(1, nb_users + 1):\n",
        "        ##id of movies that is rated by current users\n",
        "        id_movies = data[:,1][data[:,0] == id_users]\n",
        "        \n",
        "        ##rate of movies that is given by current user\n",
        "        id_ratings = data[:,2][data[:,0] == id_users]\n",
        "        \n",
        "        #inialize ratings for all movies\n",
        "        #set 0 for movies that are not rated by current users\n",
        "        ratings = np.zeros(nb_movies)\n",
        "        #movie id starts from 1, 1st movie will be 1st element in rating with index as 0\n",
        "        ratings[id_movies - 1] = id_ratings\n",
        "        new_data.append(list(ratings))\n",
        "    return new_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXWFYOOsgGCH"
      },
      "source": [
        "With the above conversion function, we convert the training set and test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8fW4Z-LnTLk"
      },
      "source": [
        "training_set = convert(training_set)\n",
        "test_set = convert(test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGObZwG4njMQ"
      },
      "source": [
        "convert data into Torch tensor because we will use Pytorch to build the auto-encoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_7jPHLvnTOz"
      },
      "source": [
        "training_set = torch.FloatTensor(training_set)\n",
        "test_set = torch.FloatTensor(test_set)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpIZhWiEnnMe",
        "outputId": "725aca80-5eff-4191-9932-7c55ae36d92f"
      },
      "source": [
        "training_set"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5., 3., 4.,  ..., 0., 0., 0.],\n",
              "        [4., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [5., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 5., 0.,  ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDMuY9qMrziQ"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P2QgzjPqnnN6",
        "outputId": "33b39d2d-0d9c-462d-bf70-d41c2f734773"
      },
      "source": [
        "test_set"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        ...,\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
              "        [0., 0., 0.,  ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIq08R2RnrzS"
      },
      "source": [
        " SAE architecture creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Hj9dauFnnRM"
      },
      "source": [
        "class SAE(nn.Module):\n",
        "    def __init__(self, ):\n",
        "        #allow to inhert all classes and methods of parent class\n",
        "        super(SAE, self).__init__()\n",
        "        #num of features from input: num of movies, 20 nodes in first hidden layer\n",
        "        self.fc1 = nn.Linear(nb_movies, 20)\n",
        "        self.fc2 = nn.Linear(20, 10)\n",
        "        #start to decoding\n",
        "        self.fc3 = nn.Linear(10, 20)\n",
        "        self.fc4 = nn.Linear(20, nb_movies)\n",
        "        self.activation = nn.Sigmoid()\n",
        "        \n",
        "    #input vector (movies rating) for a specific users\n",
        "    def forward(self, x):\n",
        "        #apply activaton fuc on first encoding layer\n",
        "        #return first encoded vector\n",
        "        x = self.activation(self.fc1(x))\n",
        "        x = self.activation(self.fc2(x))\n",
        "        x = self.activation(self.fc3(x))\n",
        "        #no need to activate the vector\n",
        "        #output the reconstrctured vector\n",
        "        x = self.fc4(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJzEZWe3nvlO"
      },
      "source": [
        " Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJ-PU53YnnTD"
      },
      "source": [
        "sae = SAE()\n",
        "#Create loss fucn object\n",
        "criterion = nn.MSELoss()\n",
        "#create optimizer object\n",
        "#parameters of all auto-encoders defined in the class\n",
        "optimizer = optim.RMSprop(sae.parameters(), lr = 0.01, weight_decay = 0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gj3FjTCgnnWE",
        "outputId": "5ce49a7b-d6cd-4c57-89e0-44d5cbe14919"
      },
      "source": [
        "# #train the SAE using pytorch only codes\n",
        "\n",
        "#loop all epochs\n",
        "nb_epoch = 200\n",
        "for epoch in range(1, nb_epoch + 1):\n",
        "    train_loss = 0\n",
        "    #exclude users who did not rate any movies\n",
        "    #define a float\n",
        "    s = 0.\n",
        "    #loop through each users\n",
        "    for id_user in range(nb_users):\n",
        "        #get all rating for current user from training_set\n",
        "        #nn does not take single dimension vector, so add a batch dimension\n",
        "        #a batch of sinlge inptu vector, update weigths after each vector\n",
        "        input = Variable(training_set[id_user]).unsqueeze(0)\n",
        "        #create target by copying input\n",
        "        target = input.clone()\n",
        "        #only look at users who rated at least 1 movie\n",
        "        if torch.sum(target.data > 0) > 0:\n",
        "            #get output from the network, a vector of predicted value\n",
        "            output = sae(input)\n",
        "            #do not compute gradient with respect to target\n",
        "            target.require_grad = False\n",
        "            #don't account the output whose initial input is 0\n",
        "            output[target == 0] = 0\n",
        "            loss = criterion(output, target)\n",
        "            #make demonitor is not zero, to add a small number\n",
        "            mean_corrector = nb_movies / float(torch.sum(target.data>0) + 1e-10)\n",
        "            #backward method to determine which direction \n",
        "            loss.backward()\n",
        "            #access the data of loss object .data[0]\n",
        "            #adjust the loss to compute relevant mean for all movies for current user\n",
        "            train_loss += np.sqrt(loss.data * mean_corrector)\n",
        "            s += 1.\n",
        "            #apply optimizer to update weights, decides the amount of weight udpates\n",
        "            optimizer.step()\n",
        "    if epoch % 10 == 0:\n",
        "        print('epoch: '+str(epoch) + ' loss: ' + str(train_loss/s))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 10 loss: tensor(1.0196)\n",
            "epoch: 20 loss: tensor(1.0162)\n",
            "epoch: 30 loss: tensor(1.0119)\n",
            "epoch: 40 loss: tensor(0.9919)\n",
            "epoch: 50 loss: tensor(0.9749)\n",
            "epoch: 60 loss: tensor(0.9629)\n",
            "epoch: 70 loss: tensor(0.9600)\n",
            "epoch: 80 loss: tensor(0.9531)\n",
            "epoch: 90 loss: tensor(0.9479)\n",
            "epoch: 100 loss: tensor(0.9430)\n",
            "epoch: 110 loss: tensor(0.9354)\n",
            "epoch: 120 loss: tensor(0.9324)\n",
            "epoch: 130 loss: tensor(0.9282)\n",
            "epoch: 140 loss: tensor(0.9251)\n",
            "epoch: 150 loss: tensor(0.9225)\n",
            "epoch: 160 loss: tensor(0.9205)\n",
            "epoch: 170 loss: tensor(0.9186)\n",
            "epoch: 180 loss: tensor(0.9163)\n",
            "epoch: 190 loss: tensor(0.9148)\n",
            "epoch: 200 loss: tensor(0.9135)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dLBXorQyn36W"
      },
      "source": [
        " SAE testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D6FE9AjonnXl",
        "outputId": "a19d0152-69bd-4091-e70e-aee27e5a70aa"
      },
      "source": [
        "#evaluation\n",
        "#loop through each users\n",
        "test_loss = 0\n",
        "s = 0.\n",
        "for id_user in range(nb_users):\n",
        "    #keep using training set\n",
        "    input = Variable(training_set[id_user]).unsqueeze(0)\n",
        "    #create target by copying input\n",
        "    target = Variable(test_set[id_user]).unsqueeze(0)\n",
        "    #only look at users who rated at least 1 movie\n",
        "    if torch.sum(target.data > 0) > 0:\n",
        "        #get output from the network, a vector of predicted value\n",
        "        output = sae(input)\n",
        "        #do not compute gradient with respect to target\n",
        "        target.require_grad = False\n",
        "        #don't account the output whose initial input is 0\n",
        "        output[target == 0] = 0\n",
        "        loss = criterion(output, target)\n",
        "        #make demonitor is not zero, to add a small number\n",
        "        mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
        "        \n",
        "        \n",
        "        #access the data of loss object .data[0]\n",
        "        #adjust the loss to compute relevant mean for all movies for current user\n",
        "        test_loss += np.sqrt(loss.data*mean_corrector)\n",
        "        s += 1.\n",
        "print('test loss: '+str(test_loss/s))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test loss: tensor(0.9553)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49-oZx7PoBuT"
      },
      "source": [
        "Prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sc3EiudEkEpk"
      },
      "source": [
        "comparing the real ratings and the predicted ratings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itDPh9XCnnbT"
      },
      "source": [
        "user_id = 0\n",
        "movie_title = movies.iloc[:nb_movies, 0:1]\n",
        "user_rating = training_set.data.numpy()[user_id, :].reshape(-1,1)\n",
        "user_target = test_set.data.numpy()[user_id, :].reshape(-1,1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyW_dHCdnneN",
        "outputId": "8dbdbd84-b3d4-464b-9754-3b6485bd0111"
      },
      "source": [
        "#to be predicted, target\n",
        "user_target[user_target>0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5., 3., 5., 5., 3., 4., 4., 3., 2., 3., 4., 2., 4., 5., 4., 3., 4.,\n",
              "       3., 3., 4., 5., 4., 3., 5., 4., 3., 3., 3., 4., 3., 1., 4., 1., 4.,\n",
              "       5., 5., 4., 3., 5., 4., 5., 3., 5., 3., 4., 5., 2., 1., 1., 4., 5.,\n",
              "       1., 5., 5., 3., 3., 1., 4., 3., 4., 5., 3., 4., 4., 1., 1., 2., 2.,\n",
              "       5., 4., 5., 2., 4., 3., 4., 4., 4., 3., 5., 5., 5., 5., 5., 3., 5.,\n",
              "       4., 4., 4., 3., 3., 5., 4., 5., 3., 3., 5., 4., 5., 4., 4., 4., 2.,\n",
              "       4., 3., 3., 1., 5., 4., 5., 2., 3., 4., 5., 4., 4., 3., 2., 5., 4.,\n",
              "       4., 5., 1., 4., 4., 2., 5., 1., 2., 5., 1., 1., 3., 2., 4., 1., 4.,\n",
              "       3.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AavMuFboHkh"
      },
      "source": [
        "user_input = Variable(training_set[user_id]).unsqueeze(0)\n",
        "# print('training input: ', len(training_set[user_id]), training_set[user_id])\n",
        "predicted = sae(user_input)\n",
        "predicted = np.round(predicted.data.numpy().reshape(-1,1), 2)\n",
        "# print('predicted: \\n', len(predicted), predicted)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Le8nhIoAoKKa"
      },
      "source": [
        "user_input = user_input.data.numpy().reshape(-1,1)\n",
        "result_array = np.hstack([movie_title, user_input, user_target, predicted])\n",
        "result_df = pd.DataFrame(data=result_array, columns=['Movie', 'User input', 'Target Rating', 'Predicted'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDKFMAq5gbPs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9b4bda7-a3c8-42b5-b499-4f40cc8681a1"
      },
      "source": [
        "prediction = sae(test_set)\n",
        "prediction"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[3.7664, 3.2248, 2.7012,  ..., 1.9749, 3.2757, 2.9450],\n",
              "        [4.5004, 4.3597, 4.0184,  ..., 2.5192, 4.1490, 3.7603],\n",
              "        [4.7525, 4.7694, 4.5102,  ..., 2.7173, 4.4670, 4.0574],\n",
              "        ...,\n",
              "        [3.6088, 3.1396, 2.7055,  ..., 1.9415, 3.2180, 2.8945],\n",
              "        [3.6088, 3.1396, 2.7055,  ..., 1.9415, 3.2180, 2.8945],\n",
              "        [3.6088, 3.1396, 2.7055,  ..., 1.9415, 3.2180, 2.8945]],\n",
              "       grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDroNpwcq02b"
      },
      "source": [
        "**The task is to predict if a user likes a movie as 1 or dislike as 0.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPu7ZUsXwjij"
      },
      "source": [
        " Binary data conversion\n",
        "convert rating 1-5 to binary 1 or 0, as the target is to predict like or not\n",
        "if not rated, set to 0\n",
        "if rate is 1 or 2, set as 0 dislike\n",
        "if rate is >= 3, set as 1 like"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9oAL8M2rcou"
      },
      "source": [
        "##so this is to make input and output data consistent\n",
        "training_set[training_set == 0] = -1\n",
        "training_set[training_set == 1] = 0\n",
        "training_set[training_set == 2] = 0\n",
        "training_set[training_set >= 3] = 1\n",
        "\n",
        "test_set[test_set == 0] = -1\n",
        "test_set[test_set == 1] = 0\n",
        "test_set[test_set == 2] = 0\n",
        "test_set[test_set >= 3] = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LWK4e4Mrcsc",
        "outputId": "423c695f-a299-469d-ff5c-7f3a767b4f8e"
      },
      "source": [
        "training_set"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.,  1.,  1.,  ..., -1., -1., -1.],\n",
              "        [ 1., -1., -1.,  ..., -1., -1., -1.],\n",
              "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "        ...,\n",
              "        [ 1., -1., -1.,  ..., -1., -1., -1.],\n",
              "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "        [-1.,  1., -1.,  ..., -1., -1., -1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWwrLtGircvw",
        "outputId": "c452c4d4-b406-4c31-b07a-f6cde0ce3fd7"
      },
      "source": [
        "test_set"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "        ...,\n",
              "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
              "        [-1., -1., -1.,  ..., -1., -1., -1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojrg8RTtr27R"
      },
      "source": [
        " RBM architecture creation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAEU9xTzr2L0"
      },
      "source": [
        "class RBM():\n",
        "    def __init__(self, nv, nh):\n",
        "        ##initialize all weights \n",
        "        ##a tensor with size of nh, nv in normal dis mean 0 var 1\n",
        "        self.W = torch.randn(nh, nv)\n",
        "        #bias for hidden nodes\n",
        "        #1st dimension is batch, 2nd is num of hidden nodes\n",
        "        self.a = torch.randn(1, nh)\n",
        "        #bias for visible nodes\n",
        "        self.b = torch.randn(1, nv)\n",
        "    #activate the hidden nodes by sampling all hiddens node, given values of visible nodes \n",
        "    def sample_h(self, x):\n",
        "        #x is values of visible nodes\n",
        "        #probablity of hiddens h to be activated, given values of visible  nodes v\n",
        "        wx = torch.mm(x, self.W.t())\n",
        "        #use sigmoid fuc to activate visible node\n",
        "        ## a is bias for hidden nodes\n",
        "        activation = wx + self.a.expand_as(wx)\n",
        "        ##ith of the vector is the probability of ith hidden nodes to be activated, \n",
        "        ##given visible values\n",
        "        p_h_given_v =torch.sigmoid(activation)\n",
        "        #samples of all hiddens nodes\n",
        "        return p_h_given_v, torch.bernoulli(p_h_given_v)\n",
        "    def sample_v(self, y):\n",
        "        #y is hidden nodes\n",
        "        #probablity of visible h to be activated, given hidden  nodes v\n",
        "        wy = torch.mm(y, self.W)\n",
        "        #use sigmoid fuc to activate hiddens nodes\n",
        "        activation = wy + self.b.expand_as(wy)\n",
        "        ##ith of the vector is the probability of ith visible nodes to be activated, \n",
        "        ##given hidden values\n",
        "        p_v_given_h =torch.sigmoid(activation)\n",
        "        #samples of all hiddens nodes\n",
        "        return p_v_given_h, torch.bernoulli(p_v_given_h)\n",
        "        \n",
        "    #visible nodes after kth interation\n",
        "    #probablity of hidden nodes after kth iteration\n",
        "    def train(self, v0, vk, ph0, phk):\n",
        "#         self.W += torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)\n",
        "        self.W += (torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)).t()\n",
        "#         self.W += torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)\n",
        "        #add zero to keep b as a tensor of 2 dimension\n",
        "        self.b += torch.sum((v0 - vk), 0)\n",
        "        self.a += torch.sum((ph0 - phk), 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OAjRBzafr-F1"
      },
      "source": [
        "Initialize RBM object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWDJnzgXr2Nm"
      },
      "source": [
        "#number of movies\n",
        "nv = len(training_set[0])\n",
        "#number of hidden nodes or num of features\n",
        "nh = 100\n",
        "batch_size = 100\n",
        "rbm = RBM(nv, nh)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bYTXxyePr_hU"
      },
      "source": [
        "Model training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odDziLuDr2Qq",
        "outputId": "39328e59-1fc3-41de-ca7f-df2923d9e732"
      },
      "source": [
        "nb_epoch = 10\n",
        "for epoch in range(1, nb_epoch+1):\n",
        "    ##loss function\n",
        "    train_loss = 0\n",
        "    #normalize the loss, define a counter\n",
        "    s = 0.\n",
        "    #implement a batch learning, \n",
        "    for id_user in range(0, nb_users - batch_size, 100):\n",
        "        #input batch values\n",
        "        vk = training_set[id_user: id_user+batch_size]\n",
        "        #target used for loss mesarue: rating \n",
        "        v0 = training_set[id_user: id_user+batch_size]\n",
        "        ##initilize probablity\n",
        "        #pho: given real rating at begining, probablity of hidden nodes\n",
        "        ph0, _ = rbm.sample_h(v0)\n",
        "        #k step of constrative divergence\n",
        "        for k in range(10):\n",
        "            _, hk = rbm.sample_h(vk)\n",
        "            _, vk = rbm.sample_v(hk)\n",
        "            #training on rating that do exist, rating as -1\n",
        "            vk[v0<0] = v0[v0<0]\n",
        "        phk, _ = rbm.sample_h(vk)\n",
        "        #update weights and bias\n",
        "        rbm.train(v0, vk, ph0, phk)\n",
        "        #update train loss\n",
        "        train_loss += torch.mean(torch.abs(v0[v0>0]-vk[v0>0]))\n",
        "        s += 1\n",
        "    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 1 loss: tensor(0.3118)\n",
            "epoch: 2 loss: tensor(0.1540)\n",
            "epoch: 3 loss: tensor(0.1498)\n",
            "epoch: 4 loss: tensor(0.1533)\n",
            "epoch: 5 loss: tensor(0.1486)\n",
            "epoch: 6 loss: tensor(0.1505)\n",
            "epoch: 7 loss: tensor(0.1585)\n",
            "epoch: 8 loss: tensor(0.1362)\n",
            "epoch: 9 loss: tensor(0.1466)\n",
            "epoch: 10 loss: tensor(0.1468)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3k5-cFIlsHn0"
      },
      "source": [
        "Test RBM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxwisItnr2Sq"
      },
      "source": [
        "##loss function\n",
        "test_loss = 0\n",
        "#normalize the loss, define a counter\n",
        "s = 0.\n",
        "#implement a batch learning, \n",
        "for id_user in range(0, nb_users):\n",
        "    #use input of train set to activate RBM\n",
        "    v_input = training_set[id_user: id_user+1]\n",
        "    #target used for loss mesarue: rating \n",
        "    v_target = test_set[id_user: id_user+1]\n",
        "    #use only 1 step to make better prediction, though used 10 steps to train\n",
        "    if len(v_target[v_target>=0]):\n",
        "        _, h = rbm.sample_h(v_input)\n",
        "        _, v_input = rbm.sample_v(h)\n",
        "        #update test loss\n",
        "        test_loss += torch.mean(torch.abs(v_target[v_target>0]-v_input[v_target>0]))\n",
        "        s += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gP3p0tuLr2Wk",
        "outputId": "a3b73ca5-ea6a-48ad-eb82-ccd1aa185254"
      },
      "source": [
        "print('test loss: ' +str(test_loss/s))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test loss: tensor(0.1521)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "St1ZifyqyjQu"
      },
      "source": [
        "Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzNGr7nglnK2",
        "outputId": "151b7e06-c7d4-4493-95cb-bda7271cf162"
      },
      "source": [
        "prediction = sae(test_set)\n",
        "prediction"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[4.8630, 4.9375, 4.7070,  ..., 2.7982, 4.5971, 4.1789],\n",
              "        [4.8599, 4.9335, 4.7028,  ..., 2.7963, 4.5941, 4.1761],\n",
              "        [4.8598, 4.9335, 4.7027,  ..., 2.7963, 4.5940, 4.1761],\n",
              "        ...,\n",
              "        [4.8598, 4.9333, 4.7026,  ..., 2.7962, 4.5939, 4.1760],\n",
              "        [4.8598, 4.9333, 4.7026,  ..., 2.7962, 4.5939, 4.1760],\n",
              "        [4.8598, 4.9333, 4.7026,  ..., 2.7962, 4.5939, 4.1760]],\n",
              "       grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRxyUtDHrfl5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IcIm9j8rfpU",
        "outputId": "91c80359-d701-4291-afba-3adbf9e64933"
      },
      "source": [
        "t=prediction.detach().numpy()\n",
        "t"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[4.862994 , 4.9375277, 4.7069936, ..., 2.7981968, 4.597098 ,\n",
              "        4.178917 ],\n",
              "       [4.8599215, 4.9335485, 4.702801 , ..., 2.7963388, 4.5940957,\n",
              "        4.1761236],\n",
              "       [4.859848 , 4.933453 , 4.702702 , ..., 2.7962945, 4.594024 ,\n",
              "        4.176057 ],\n",
              "       ...,\n",
              "       [4.8597574, 4.9333315, 4.702571 , ..., 2.7962372, 4.5939317,\n",
              "        4.1759706],\n",
              "       [4.8597574, 4.9333315, 4.702571 , ..., 2.7962372, 4.5939317,\n",
              "        4.1759706],\n",
              "       [4.8597574, 4.9333315, 4.702571 , ..., 2.7962372, 4.5939326,\n",
              "        4.1759706]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "id": "eOJXz8tUsTLH",
        "outputId": "ac3ec254-574a-4b7b-a233-88a6ad3af2c4"
      },
      "source": [
        "df3=pd.DataFrame(t)\n",
        "df3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>1642</th>\n",
              "      <th>1643</th>\n",
              "      <th>1644</th>\n",
              "      <th>1645</th>\n",
              "      <th>1646</th>\n",
              "      <th>1647</th>\n",
              "      <th>1648</th>\n",
              "      <th>1649</th>\n",
              "      <th>1650</th>\n",
              "      <th>1651</th>\n",
              "      <th>1652</th>\n",
              "      <th>1653</th>\n",
              "      <th>1654</th>\n",
              "      <th>1655</th>\n",
              "      <th>1656</th>\n",
              "      <th>1657</th>\n",
              "      <th>1658</th>\n",
              "      <th>1659</th>\n",
              "      <th>1660</th>\n",
              "      <th>1661</th>\n",
              "      <th>1662</th>\n",
              "      <th>1663</th>\n",
              "      <th>1664</th>\n",
              "      <th>1665</th>\n",
              "      <th>1666</th>\n",
              "      <th>1667</th>\n",
              "      <th>1668</th>\n",
              "      <th>1669</th>\n",
              "      <th>1670</th>\n",
              "      <th>1671</th>\n",
              "      <th>1672</th>\n",
              "      <th>1673</th>\n",
              "      <th>1674</th>\n",
              "      <th>1675</th>\n",
              "      <th>1676</th>\n",
              "      <th>1677</th>\n",
              "      <th>1678</th>\n",
              "      <th>1679</th>\n",
              "      <th>1680</th>\n",
              "      <th>1681</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.862994</td>\n",
              "      <td>4.937528</td>\n",
              "      <td>4.706994</td>\n",
              "      <td>4.884969</td>\n",
              "      <td>4.724471</td>\n",
              "      <td>5.493420</td>\n",
              "      <td>4.676805</td>\n",
              "      <td>4.260369</td>\n",
              "      <td>3.736928</td>\n",
              "      <td>4.718725</td>\n",
              "      <td>5.127321</td>\n",
              "      <td>5.038467</td>\n",
              "      <td>3.287802</td>\n",
              "      <td>4.239405</td>\n",
              "      <td>5.117038</td>\n",
              "      <td>4.753840</td>\n",
              "      <td>5.064784</td>\n",
              "      <td>4.320230</td>\n",
              "      <td>5.626140</td>\n",
              "      <td>4.314803</td>\n",
              "      <td>3.973017</td>\n",
              "      <td>5.585716</td>\n",
              "      <td>4.794350</td>\n",
              "      <td>4.776856</td>\n",
              "      <td>4.655086</td>\n",
              "      <td>4.582791</td>\n",
              "      <td>4.656462</td>\n",
              "      <td>5.136333</td>\n",
              "      <td>3.975565</td>\n",
              "      <td>5.362119</td>\n",
              "      <td>5.269287</td>\n",
              "      <td>5.424236</td>\n",
              "      <td>4.915004</td>\n",
              "      <td>4.190876</td>\n",
              "      <td>3.538246</td>\n",
              "      <td>3.154755</td>\n",
              "      <td>3.521849</td>\n",
              "      <td>4.476736</td>\n",
              "      <td>4.805713</td>\n",
              "      <td>3.848466</td>\n",
              "      <td>...</td>\n",
              "      <td>5.376429</td>\n",
              "      <td>2.494873</td>\n",
              "      <td>6.242023</td>\n",
              "      <td>5.841465</td>\n",
              "      <td>4.655827</td>\n",
              "      <td>3.100961</td>\n",
              "      <td>4.646173</td>\n",
              "      <td>6.236533</td>\n",
              "      <td>6.245732</td>\n",
              "      <td>2.676255</td>\n",
              "      <td>6.569363</td>\n",
              "      <td>1.300108</td>\n",
              "      <td>2.793954</td>\n",
              "      <td>5.317999</td>\n",
              "      <td>4.308992</td>\n",
              "      <td>4.586832</td>\n",
              "      <td>1.286630</td>\n",
              "      <td>2.610664</td>\n",
              "      <td>1.348546</td>\n",
              "      <td>4.244437</td>\n",
              "      <td>2.945614</td>\n",
              "      <td>4.693539</td>\n",
              "      <td>2.950355</td>\n",
              "      <td>2.964138</td>\n",
              "      <td>4.420614</td>\n",
              "      <td>4.401104</td>\n",
              "      <td>2.940700</td>\n",
              "      <td>4.396425</td>\n",
              "      <td>1.373414</td>\n",
              "      <td>3.246153</td>\n",
              "      <td>3.552071</td>\n",
              "      <td>5.100080</td>\n",
              "      <td>3.694463</td>\n",
              "      <td>2.463468</td>\n",
              "      <td>4.607857</td>\n",
              "      <td>1.369591</td>\n",
              "      <td>4.147149</td>\n",
              "      <td>2.798197</td>\n",
              "      <td>4.597098</td>\n",
              "      <td>4.178917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.859921</td>\n",
              "      <td>4.933548</td>\n",
              "      <td>4.702801</td>\n",
              "      <td>4.881745</td>\n",
              "      <td>4.720995</td>\n",
              "      <td>5.489340</td>\n",
              "      <td>4.674518</td>\n",
              "      <td>4.258825</td>\n",
              "      <td>3.736241</td>\n",
              "      <td>4.716664</td>\n",
              "      <td>5.124128</td>\n",
              "      <td>5.036795</td>\n",
              "      <td>3.287267</td>\n",
              "      <td>4.238099</td>\n",
              "      <td>5.114026</td>\n",
              "      <td>4.750484</td>\n",
              "      <td>5.060625</td>\n",
              "      <td>4.317459</td>\n",
              "      <td>5.622271</td>\n",
              "      <td>4.312119</td>\n",
              "      <td>3.970190</td>\n",
              "      <td>5.582136</td>\n",
              "      <td>4.792311</td>\n",
              "      <td>4.773793</td>\n",
              "      <td>4.652112</td>\n",
              "      <td>4.579904</td>\n",
              "      <td>4.652856</td>\n",
              "      <td>5.133636</td>\n",
              "      <td>3.972624</td>\n",
              "      <td>5.359056</td>\n",
              "      <td>5.265015</td>\n",
              "      <td>5.420805</td>\n",
              "      <td>4.911420</td>\n",
              "      <td>4.188023</td>\n",
              "      <td>3.535252</td>\n",
              "      <td>3.152486</td>\n",
              "      <td>3.519677</td>\n",
              "      <td>4.473520</td>\n",
              "      <td>4.802236</td>\n",
              "      <td>3.845858</td>\n",
              "      <td>...</td>\n",
              "      <td>5.372820</td>\n",
              "      <td>2.493190</td>\n",
              "      <td>6.237966</td>\n",
              "      <td>5.837593</td>\n",
              "      <td>4.652786</td>\n",
              "      <td>3.098937</td>\n",
              "      <td>4.643145</td>\n",
              "      <td>6.232471</td>\n",
              "      <td>6.241661</td>\n",
              "      <td>2.674235</td>\n",
              "      <td>6.564980</td>\n",
              "      <td>1.299243</td>\n",
              "      <td>2.792080</td>\n",
              "      <td>5.314195</td>\n",
              "      <td>4.306157</td>\n",
              "      <td>4.583652</td>\n",
              "      <td>1.285775</td>\n",
              "      <td>2.608912</td>\n",
              "      <td>1.347634</td>\n",
              "      <td>4.241521</td>\n",
              "      <td>2.943668</td>\n",
              "      <td>4.690333</td>\n",
              "      <td>2.948406</td>\n",
              "      <td>2.962174</td>\n",
              "      <td>4.417693</td>\n",
              "      <td>4.398197</td>\n",
              "      <td>2.938754</td>\n",
              "      <td>4.393523</td>\n",
              "      <td>1.372502</td>\n",
              "      <td>3.244016</td>\n",
              "      <td>3.549670</td>\n",
              "      <td>5.096644</td>\n",
              "      <td>3.691964</td>\n",
              "      <td>2.461805</td>\n",
              "      <td>4.604849</td>\n",
              "      <td>1.368682</td>\n",
              "      <td>4.144380</td>\n",
              "      <td>2.796339</td>\n",
              "      <td>4.594096</td>\n",
              "      <td>4.176124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.859848</td>\n",
              "      <td>4.933453</td>\n",
              "      <td>4.702702</td>\n",
              "      <td>4.881670</td>\n",
              "      <td>4.720913</td>\n",
              "      <td>5.489244</td>\n",
              "      <td>4.674463</td>\n",
              "      <td>4.258789</td>\n",
              "      <td>3.736225</td>\n",
              "      <td>4.716615</td>\n",
              "      <td>5.124053</td>\n",
              "      <td>5.036755</td>\n",
              "      <td>3.287254</td>\n",
              "      <td>4.238068</td>\n",
              "      <td>5.113955</td>\n",
              "      <td>4.750403</td>\n",
              "      <td>5.060525</td>\n",
              "      <td>4.317393</td>\n",
              "      <td>5.622178</td>\n",
              "      <td>4.312055</td>\n",
              "      <td>3.970123</td>\n",
              "      <td>5.582051</td>\n",
              "      <td>4.792262</td>\n",
              "      <td>4.773721</td>\n",
              "      <td>4.652041</td>\n",
              "      <td>4.579835</td>\n",
              "      <td>4.652771</td>\n",
              "      <td>5.133572</td>\n",
              "      <td>3.972554</td>\n",
              "      <td>5.358983</td>\n",
              "      <td>5.264914</td>\n",
              "      <td>5.420722</td>\n",
              "      <td>4.911335</td>\n",
              "      <td>4.187955</td>\n",
              "      <td>3.535181</td>\n",
              "      <td>3.152431</td>\n",
              "      <td>3.519625</td>\n",
              "      <td>4.473444</td>\n",
              "      <td>4.802153</td>\n",
              "      <td>3.845796</td>\n",
              "      <td>...</td>\n",
              "      <td>5.372735</td>\n",
              "      <td>2.493150</td>\n",
              "      <td>6.237870</td>\n",
              "      <td>5.837501</td>\n",
              "      <td>4.652714</td>\n",
              "      <td>3.098889</td>\n",
              "      <td>4.643073</td>\n",
              "      <td>6.232375</td>\n",
              "      <td>6.241565</td>\n",
              "      <td>2.674188</td>\n",
              "      <td>6.564874</td>\n",
              "      <td>1.299222</td>\n",
              "      <td>2.792036</td>\n",
              "      <td>5.314104</td>\n",
              "      <td>4.306089</td>\n",
              "      <td>4.583576</td>\n",
              "      <td>1.285754</td>\n",
              "      <td>2.608870</td>\n",
              "      <td>1.347612</td>\n",
              "      <td>4.241452</td>\n",
              "      <td>2.943622</td>\n",
              "      <td>4.690257</td>\n",
              "      <td>2.948359</td>\n",
              "      <td>2.962126</td>\n",
              "      <td>4.417624</td>\n",
              "      <td>4.398128</td>\n",
              "      <td>2.938708</td>\n",
              "      <td>4.393454</td>\n",
              "      <td>1.372480</td>\n",
              "      <td>3.243964</td>\n",
              "      <td>3.549613</td>\n",
              "      <td>5.096560</td>\n",
              "      <td>3.691904</td>\n",
              "      <td>2.461766</td>\n",
              "      <td>4.604777</td>\n",
              "      <td>1.368661</td>\n",
              "      <td>4.144314</td>\n",
              "      <td>2.796294</td>\n",
              "      <td>4.594024</td>\n",
              "      <td>4.176057</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.859803</td>\n",
              "      <td>4.933394</td>\n",
              "      <td>4.702638</td>\n",
              "      <td>4.881620</td>\n",
              "      <td>4.720860</td>\n",
              "      <td>5.489182</td>\n",
              "      <td>4.674428</td>\n",
              "      <td>4.258766</td>\n",
              "      <td>3.736216</td>\n",
              "      <td>4.716584</td>\n",
              "      <td>5.124004</td>\n",
              "      <td>5.036730</td>\n",
              "      <td>3.287247</td>\n",
              "      <td>4.238049</td>\n",
              "      <td>5.113909</td>\n",
              "      <td>4.750352</td>\n",
              "      <td>5.060462</td>\n",
              "      <td>4.317351</td>\n",
              "      <td>5.622120</td>\n",
              "      <td>4.312015</td>\n",
              "      <td>3.970080</td>\n",
              "      <td>5.581997</td>\n",
              "      <td>4.792232</td>\n",
              "      <td>4.773674</td>\n",
              "      <td>4.651996</td>\n",
              "      <td>4.579791</td>\n",
              "      <td>4.652716</td>\n",
              "      <td>5.133530</td>\n",
              "      <td>3.972509</td>\n",
              "      <td>5.358936</td>\n",
              "      <td>5.264849</td>\n",
              "      <td>5.420671</td>\n",
              "      <td>4.911280</td>\n",
              "      <td>4.187912</td>\n",
              "      <td>3.535135</td>\n",
              "      <td>3.152397</td>\n",
              "      <td>3.519592</td>\n",
              "      <td>4.473394</td>\n",
              "      <td>4.802100</td>\n",
              "      <td>3.845757</td>\n",
              "      <td>...</td>\n",
              "      <td>5.372680</td>\n",
              "      <td>2.493124</td>\n",
              "      <td>6.237807</td>\n",
              "      <td>5.837442</td>\n",
              "      <td>4.652668</td>\n",
              "      <td>3.098858</td>\n",
              "      <td>4.643027</td>\n",
              "      <td>6.232314</td>\n",
              "      <td>6.241502</td>\n",
              "      <td>2.674157</td>\n",
              "      <td>6.564807</td>\n",
              "      <td>1.299209</td>\n",
              "      <td>2.792007</td>\n",
              "      <td>5.314046</td>\n",
              "      <td>4.306046</td>\n",
              "      <td>4.583529</td>\n",
              "      <td>1.285741</td>\n",
              "      <td>2.608843</td>\n",
              "      <td>1.347598</td>\n",
              "      <td>4.241407</td>\n",
              "      <td>2.943592</td>\n",
              "      <td>4.690208</td>\n",
              "      <td>2.948330</td>\n",
              "      <td>2.962097</td>\n",
              "      <td>4.417580</td>\n",
              "      <td>4.398084</td>\n",
              "      <td>2.938679</td>\n",
              "      <td>4.393410</td>\n",
              "      <td>1.372467</td>\n",
              "      <td>3.243932</td>\n",
              "      <td>3.549576</td>\n",
              "      <td>5.096510</td>\n",
              "      <td>3.691866</td>\n",
              "      <td>2.461740</td>\n",
              "      <td>4.604731</td>\n",
              "      <td>1.368647</td>\n",
              "      <td>4.144272</td>\n",
              "      <td>2.796266</td>\n",
              "      <td>4.593979</td>\n",
              "      <td>4.176015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.839566</td>\n",
              "      <td>4.906487</td>\n",
              "      <td>4.673734</td>\n",
              "      <td>4.859522</td>\n",
              "      <td>4.697164</td>\n",
              "      <td>5.461495</td>\n",
              "      <td>4.659163</td>\n",
              "      <td>4.248903</td>\n",
              "      <td>3.732414</td>\n",
              "      <td>4.702613</td>\n",
              "      <td>5.102023</td>\n",
              "      <td>5.025600</td>\n",
              "      <td>3.284369</td>\n",
              "      <td>4.229522</td>\n",
              "      <td>5.093278</td>\n",
              "      <td>4.727492</td>\n",
              "      <td>5.031925</td>\n",
              "      <td>4.298538</td>\n",
              "      <td>5.595788</td>\n",
              "      <td>4.294236</td>\n",
              "      <td>3.950945</td>\n",
              "      <td>5.557889</td>\n",
              "      <td>4.778316</td>\n",
              "      <td>4.752837</td>\n",
              "      <td>4.631545</td>\n",
              "      <td>4.560231</td>\n",
              "      <td>4.628208</td>\n",
              "      <td>5.115135</td>\n",
              "      <td>3.952363</td>\n",
              "      <td>5.338146</td>\n",
              "      <td>5.236044</td>\n",
              "      <td>5.397391</td>\n",
              "      <td>4.886891</td>\n",
              "      <td>4.168469</td>\n",
              "      <td>3.514327</td>\n",
              "      <td>3.136702</td>\n",
              "      <td>3.504885</td>\n",
              "      <td>4.451318</td>\n",
              "      <td>4.778331</td>\n",
              "      <td>3.827891</td>\n",
              "      <td>...</td>\n",
              "      <td>5.348068</td>\n",
              "      <td>2.481666</td>\n",
              "      <td>6.210238</td>\n",
              "      <td>5.811108</td>\n",
              "      <td>4.632013</td>\n",
              "      <td>3.085107</td>\n",
              "      <td>4.622442</td>\n",
              "      <td>6.204725</td>\n",
              "      <td>6.213830</td>\n",
              "      <td>2.660320</td>\n",
              "      <td>6.534989</td>\n",
              "      <td>1.293328</td>\n",
              "      <td>2.779252</td>\n",
              "      <td>5.288122</td>\n",
              "      <td>4.286778</td>\n",
              "      <td>4.561871</td>\n",
              "      <td>1.279928</td>\n",
              "      <td>2.596929</td>\n",
              "      <td>1.341407</td>\n",
              "      <td>4.221609</td>\n",
              "      <td>2.930375</td>\n",
              "      <td>4.668358</td>\n",
              "      <td>2.935075</td>\n",
              "      <td>2.948737</td>\n",
              "      <td>4.397736</td>\n",
              "      <td>4.378317</td>\n",
              "      <td>2.925451</td>\n",
              "      <td>4.373680</td>\n",
              "      <td>1.366262</td>\n",
              "      <td>3.229410</td>\n",
              "      <td>3.533222</td>\n",
              "      <td>5.073131</td>\n",
              "      <td>3.674855</td>\n",
              "      <td>2.450433</td>\n",
              "      <td>4.584295</td>\n",
              "      <td>1.362469</td>\n",
              "      <td>4.125450</td>\n",
              "      <td>2.783630</td>\n",
              "      <td>4.573580</td>\n",
              "      <td>4.157022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>938</th>\n",
              "      <td>4.859757</td>\n",
              "      <td>4.933331</td>\n",
              "      <td>4.702571</td>\n",
              "      <td>4.881569</td>\n",
              "      <td>4.720805</td>\n",
              "      <td>5.489118</td>\n",
              "      <td>4.674394</td>\n",
              "      <td>4.258744</td>\n",
              "      <td>3.736208</td>\n",
              "      <td>4.716552</td>\n",
              "      <td>5.123953</td>\n",
              "      <td>5.036705</td>\n",
              "      <td>3.287241</td>\n",
              "      <td>4.238029</td>\n",
              "      <td>5.113861</td>\n",
              "      <td>4.750299</td>\n",
              "      <td>5.060395</td>\n",
              "      <td>4.317307</td>\n",
              "      <td>5.622059</td>\n",
              "      <td>4.311975</td>\n",
              "      <td>3.970036</td>\n",
              "      <td>5.581942</td>\n",
              "      <td>4.792199</td>\n",
              "      <td>4.773626</td>\n",
              "      <td>4.651949</td>\n",
              "      <td>4.579746</td>\n",
              "      <td>4.652658</td>\n",
              "      <td>5.133488</td>\n",
              "      <td>3.972462</td>\n",
              "      <td>5.358889</td>\n",
              "      <td>5.264783</td>\n",
              "      <td>5.420617</td>\n",
              "      <td>4.911223</td>\n",
              "      <td>4.187867</td>\n",
              "      <td>3.535086</td>\n",
              "      <td>3.152360</td>\n",
              "      <td>3.519558</td>\n",
              "      <td>4.473343</td>\n",
              "      <td>4.802044</td>\n",
              "      <td>3.845715</td>\n",
              "      <td>...</td>\n",
              "      <td>5.372623</td>\n",
              "      <td>2.493097</td>\n",
              "      <td>6.237744</td>\n",
              "      <td>5.837381</td>\n",
              "      <td>4.652620</td>\n",
              "      <td>3.098827</td>\n",
              "      <td>4.642980</td>\n",
              "      <td>6.232249</td>\n",
              "      <td>6.241438</td>\n",
              "      <td>2.674124</td>\n",
              "      <td>6.564740</td>\n",
              "      <td>1.299195</td>\n",
              "      <td>2.791978</td>\n",
              "      <td>5.313987</td>\n",
              "      <td>4.306002</td>\n",
              "      <td>4.583478</td>\n",
              "      <td>1.285728</td>\n",
              "      <td>2.608816</td>\n",
              "      <td>1.347584</td>\n",
              "      <td>4.241362</td>\n",
              "      <td>2.943562</td>\n",
              "      <td>4.690157</td>\n",
              "      <td>2.948299</td>\n",
              "      <td>2.962066</td>\n",
              "      <td>4.417534</td>\n",
              "      <td>4.398038</td>\n",
              "      <td>2.938648</td>\n",
              "      <td>4.393365</td>\n",
              "      <td>1.372452</td>\n",
              "      <td>3.243899</td>\n",
              "      <td>3.549538</td>\n",
              "      <td>5.096456</td>\n",
              "      <td>3.691827</td>\n",
              "      <td>2.461714</td>\n",
              "      <td>4.604684</td>\n",
              "      <td>1.368633</td>\n",
              "      <td>4.144229</td>\n",
              "      <td>2.796237</td>\n",
              "      <td>4.593933</td>\n",
              "      <td>4.175971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>939</th>\n",
              "      <td>4.859757</td>\n",
              "      <td>4.933331</td>\n",
              "      <td>4.702571</td>\n",
              "      <td>4.881569</td>\n",
              "      <td>4.720805</td>\n",
              "      <td>5.489118</td>\n",
              "      <td>4.674394</td>\n",
              "      <td>4.258744</td>\n",
              "      <td>3.736208</td>\n",
              "      <td>4.716552</td>\n",
              "      <td>5.123953</td>\n",
              "      <td>5.036705</td>\n",
              "      <td>3.287241</td>\n",
              "      <td>4.238029</td>\n",
              "      <td>5.113861</td>\n",
              "      <td>4.750299</td>\n",
              "      <td>5.060395</td>\n",
              "      <td>4.317307</td>\n",
              "      <td>5.622059</td>\n",
              "      <td>4.311975</td>\n",
              "      <td>3.970036</td>\n",
              "      <td>5.581942</td>\n",
              "      <td>4.792199</td>\n",
              "      <td>4.773626</td>\n",
              "      <td>4.651949</td>\n",
              "      <td>4.579746</td>\n",
              "      <td>4.652658</td>\n",
              "      <td>5.133488</td>\n",
              "      <td>3.972462</td>\n",
              "      <td>5.358889</td>\n",
              "      <td>5.264783</td>\n",
              "      <td>5.420617</td>\n",
              "      <td>4.911223</td>\n",
              "      <td>4.187867</td>\n",
              "      <td>3.535086</td>\n",
              "      <td>3.152360</td>\n",
              "      <td>3.519558</td>\n",
              "      <td>4.473343</td>\n",
              "      <td>4.802044</td>\n",
              "      <td>3.845715</td>\n",
              "      <td>...</td>\n",
              "      <td>5.372623</td>\n",
              "      <td>2.493097</td>\n",
              "      <td>6.237744</td>\n",
              "      <td>5.837381</td>\n",
              "      <td>4.652620</td>\n",
              "      <td>3.098827</td>\n",
              "      <td>4.642980</td>\n",
              "      <td>6.232249</td>\n",
              "      <td>6.241438</td>\n",
              "      <td>2.674124</td>\n",
              "      <td>6.564740</td>\n",
              "      <td>1.299195</td>\n",
              "      <td>2.791978</td>\n",
              "      <td>5.313987</td>\n",
              "      <td>4.306002</td>\n",
              "      <td>4.583478</td>\n",
              "      <td>1.285728</td>\n",
              "      <td>2.608816</td>\n",
              "      <td>1.347584</td>\n",
              "      <td>4.241362</td>\n",
              "      <td>2.943562</td>\n",
              "      <td>4.690157</td>\n",
              "      <td>2.948299</td>\n",
              "      <td>2.962066</td>\n",
              "      <td>4.417534</td>\n",
              "      <td>4.398038</td>\n",
              "      <td>2.938648</td>\n",
              "      <td>4.393365</td>\n",
              "      <td>1.372452</td>\n",
              "      <td>3.243899</td>\n",
              "      <td>3.549538</td>\n",
              "      <td>5.096456</td>\n",
              "      <td>3.691827</td>\n",
              "      <td>2.461714</td>\n",
              "      <td>4.604684</td>\n",
              "      <td>1.368633</td>\n",
              "      <td>4.144229</td>\n",
              "      <td>2.796237</td>\n",
              "      <td>4.593933</td>\n",
              "      <td>4.175971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>940</th>\n",
              "      <td>4.859757</td>\n",
              "      <td>4.933331</td>\n",
              "      <td>4.702571</td>\n",
              "      <td>4.881569</td>\n",
              "      <td>4.720805</td>\n",
              "      <td>5.489118</td>\n",
              "      <td>4.674394</td>\n",
              "      <td>4.258744</td>\n",
              "      <td>3.736208</td>\n",
              "      <td>4.716552</td>\n",
              "      <td>5.123953</td>\n",
              "      <td>5.036705</td>\n",
              "      <td>3.287241</td>\n",
              "      <td>4.238029</td>\n",
              "      <td>5.113861</td>\n",
              "      <td>4.750299</td>\n",
              "      <td>5.060395</td>\n",
              "      <td>4.317307</td>\n",
              "      <td>5.622059</td>\n",
              "      <td>4.311975</td>\n",
              "      <td>3.970036</td>\n",
              "      <td>5.581942</td>\n",
              "      <td>4.792199</td>\n",
              "      <td>4.773626</td>\n",
              "      <td>4.651949</td>\n",
              "      <td>4.579746</td>\n",
              "      <td>4.652658</td>\n",
              "      <td>5.133488</td>\n",
              "      <td>3.972462</td>\n",
              "      <td>5.358889</td>\n",
              "      <td>5.264783</td>\n",
              "      <td>5.420617</td>\n",
              "      <td>4.911223</td>\n",
              "      <td>4.187867</td>\n",
              "      <td>3.535086</td>\n",
              "      <td>3.152360</td>\n",
              "      <td>3.519558</td>\n",
              "      <td>4.473343</td>\n",
              "      <td>4.802044</td>\n",
              "      <td>3.845715</td>\n",
              "      <td>...</td>\n",
              "      <td>5.372623</td>\n",
              "      <td>2.493097</td>\n",
              "      <td>6.237744</td>\n",
              "      <td>5.837381</td>\n",
              "      <td>4.652620</td>\n",
              "      <td>3.098827</td>\n",
              "      <td>4.642980</td>\n",
              "      <td>6.232249</td>\n",
              "      <td>6.241438</td>\n",
              "      <td>2.674124</td>\n",
              "      <td>6.564740</td>\n",
              "      <td>1.299195</td>\n",
              "      <td>2.791978</td>\n",
              "      <td>5.313987</td>\n",
              "      <td>4.306002</td>\n",
              "      <td>4.583478</td>\n",
              "      <td>1.285728</td>\n",
              "      <td>2.608816</td>\n",
              "      <td>1.347584</td>\n",
              "      <td>4.241362</td>\n",
              "      <td>2.943562</td>\n",
              "      <td>4.690157</td>\n",
              "      <td>2.948299</td>\n",
              "      <td>2.962066</td>\n",
              "      <td>4.417534</td>\n",
              "      <td>4.398038</td>\n",
              "      <td>2.938648</td>\n",
              "      <td>4.393365</td>\n",
              "      <td>1.372452</td>\n",
              "      <td>3.243899</td>\n",
              "      <td>3.549538</td>\n",
              "      <td>5.096456</td>\n",
              "      <td>3.691827</td>\n",
              "      <td>2.461714</td>\n",
              "      <td>4.604684</td>\n",
              "      <td>1.368633</td>\n",
              "      <td>4.144229</td>\n",
              "      <td>2.796237</td>\n",
              "      <td>4.593932</td>\n",
              "      <td>4.175971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>941</th>\n",
              "      <td>4.859757</td>\n",
              "      <td>4.933331</td>\n",
              "      <td>4.702571</td>\n",
              "      <td>4.881569</td>\n",
              "      <td>4.720805</td>\n",
              "      <td>5.489118</td>\n",
              "      <td>4.674394</td>\n",
              "      <td>4.258744</td>\n",
              "      <td>3.736208</td>\n",
              "      <td>4.716552</td>\n",
              "      <td>5.123953</td>\n",
              "      <td>5.036705</td>\n",
              "      <td>3.287241</td>\n",
              "      <td>4.238029</td>\n",
              "      <td>5.113861</td>\n",
              "      <td>4.750299</td>\n",
              "      <td>5.060395</td>\n",
              "      <td>4.317307</td>\n",
              "      <td>5.622059</td>\n",
              "      <td>4.311975</td>\n",
              "      <td>3.970036</td>\n",
              "      <td>5.581942</td>\n",
              "      <td>4.792199</td>\n",
              "      <td>4.773626</td>\n",
              "      <td>4.651949</td>\n",
              "      <td>4.579746</td>\n",
              "      <td>4.652658</td>\n",
              "      <td>5.133488</td>\n",
              "      <td>3.972462</td>\n",
              "      <td>5.358889</td>\n",
              "      <td>5.264783</td>\n",
              "      <td>5.420617</td>\n",
              "      <td>4.911223</td>\n",
              "      <td>4.187867</td>\n",
              "      <td>3.535086</td>\n",
              "      <td>3.152360</td>\n",
              "      <td>3.519558</td>\n",
              "      <td>4.473343</td>\n",
              "      <td>4.802044</td>\n",
              "      <td>3.845715</td>\n",
              "      <td>...</td>\n",
              "      <td>5.372623</td>\n",
              "      <td>2.493097</td>\n",
              "      <td>6.237744</td>\n",
              "      <td>5.837381</td>\n",
              "      <td>4.652620</td>\n",
              "      <td>3.098827</td>\n",
              "      <td>4.642980</td>\n",
              "      <td>6.232249</td>\n",
              "      <td>6.241438</td>\n",
              "      <td>2.674124</td>\n",
              "      <td>6.564740</td>\n",
              "      <td>1.299195</td>\n",
              "      <td>2.791978</td>\n",
              "      <td>5.313987</td>\n",
              "      <td>4.306002</td>\n",
              "      <td>4.583478</td>\n",
              "      <td>1.285728</td>\n",
              "      <td>2.608816</td>\n",
              "      <td>1.347584</td>\n",
              "      <td>4.241362</td>\n",
              "      <td>2.943562</td>\n",
              "      <td>4.690157</td>\n",
              "      <td>2.948299</td>\n",
              "      <td>2.962066</td>\n",
              "      <td>4.417534</td>\n",
              "      <td>4.398038</td>\n",
              "      <td>2.938648</td>\n",
              "      <td>4.393365</td>\n",
              "      <td>1.372452</td>\n",
              "      <td>3.243899</td>\n",
              "      <td>3.549538</td>\n",
              "      <td>5.096456</td>\n",
              "      <td>3.691827</td>\n",
              "      <td>2.461714</td>\n",
              "      <td>4.604684</td>\n",
              "      <td>1.368633</td>\n",
              "      <td>4.144229</td>\n",
              "      <td>2.796237</td>\n",
              "      <td>4.593932</td>\n",
              "      <td>4.175971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>942</th>\n",
              "      <td>4.859757</td>\n",
              "      <td>4.933331</td>\n",
              "      <td>4.702571</td>\n",
              "      <td>4.881569</td>\n",
              "      <td>4.720805</td>\n",
              "      <td>5.489118</td>\n",
              "      <td>4.674394</td>\n",
              "      <td>4.258744</td>\n",
              "      <td>3.736208</td>\n",
              "      <td>4.716552</td>\n",
              "      <td>5.123953</td>\n",
              "      <td>5.036705</td>\n",
              "      <td>3.287241</td>\n",
              "      <td>4.238029</td>\n",
              "      <td>5.113861</td>\n",
              "      <td>4.750299</td>\n",
              "      <td>5.060395</td>\n",
              "      <td>4.317307</td>\n",
              "      <td>5.622059</td>\n",
              "      <td>4.311975</td>\n",
              "      <td>3.970036</td>\n",
              "      <td>5.581942</td>\n",
              "      <td>4.792199</td>\n",
              "      <td>4.773626</td>\n",
              "      <td>4.651949</td>\n",
              "      <td>4.579746</td>\n",
              "      <td>4.652658</td>\n",
              "      <td>5.133488</td>\n",
              "      <td>3.972462</td>\n",
              "      <td>5.358889</td>\n",
              "      <td>5.264783</td>\n",
              "      <td>5.420617</td>\n",
              "      <td>4.911223</td>\n",
              "      <td>4.187867</td>\n",
              "      <td>3.535086</td>\n",
              "      <td>3.152360</td>\n",
              "      <td>3.519558</td>\n",
              "      <td>4.473343</td>\n",
              "      <td>4.802044</td>\n",
              "      <td>3.845715</td>\n",
              "      <td>...</td>\n",
              "      <td>5.372623</td>\n",
              "      <td>2.493097</td>\n",
              "      <td>6.237744</td>\n",
              "      <td>5.837381</td>\n",
              "      <td>4.652620</td>\n",
              "      <td>3.098827</td>\n",
              "      <td>4.642980</td>\n",
              "      <td>6.232249</td>\n",
              "      <td>6.241438</td>\n",
              "      <td>2.674124</td>\n",
              "      <td>6.564740</td>\n",
              "      <td>1.299195</td>\n",
              "      <td>2.791978</td>\n",
              "      <td>5.313987</td>\n",
              "      <td>4.306002</td>\n",
              "      <td>4.583478</td>\n",
              "      <td>1.285728</td>\n",
              "      <td>2.608816</td>\n",
              "      <td>1.347584</td>\n",
              "      <td>4.241362</td>\n",
              "      <td>2.943562</td>\n",
              "      <td>4.690157</td>\n",
              "      <td>2.948299</td>\n",
              "      <td>2.962066</td>\n",
              "      <td>4.417534</td>\n",
              "      <td>4.398038</td>\n",
              "      <td>2.938648</td>\n",
              "      <td>4.393365</td>\n",
              "      <td>1.372452</td>\n",
              "      <td>3.243899</td>\n",
              "      <td>3.549538</td>\n",
              "      <td>5.096456</td>\n",
              "      <td>3.691827</td>\n",
              "      <td>2.461714</td>\n",
              "      <td>4.604684</td>\n",
              "      <td>1.368633</td>\n",
              "      <td>4.144229</td>\n",
              "      <td>2.796237</td>\n",
              "      <td>4.593933</td>\n",
              "      <td>4.175971</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>943 rows × 1682 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         0         1         2     ...      1679      1680      1681\n",
              "0    4.862994  4.937528  4.706994  ...  2.798197  4.597098  4.178917\n",
              "1    4.859921  4.933548  4.702801  ...  2.796339  4.594096  4.176124\n",
              "2    4.859848  4.933453  4.702702  ...  2.796294  4.594024  4.176057\n",
              "3    4.859803  4.933394  4.702638  ...  2.796266  4.593979  4.176015\n",
              "4    4.839566  4.906487  4.673734  ...  2.783630  4.573580  4.157022\n",
              "..        ...       ...       ...  ...       ...       ...       ...\n",
              "938  4.859757  4.933331  4.702571  ...  2.796237  4.593933  4.175971\n",
              "939  4.859757  4.933331  4.702571  ...  2.796237  4.593933  4.175971\n",
              "940  4.859757  4.933331  4.702571  ...  2.796237  4.593932  4.175971\n",
              "941  4.859757  4.933331  4.702571  ...  2.796237  4.593932  4.175971\n",
              "942  4.859757  4.933331  4.702571  ...  2.796237  4.593933  4.175971\n",
              "\n",
              "[943 rows x 1682 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJKSE4-k-alL"
      },
      "source": [
        "#Pearson correlation coefficient"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 579
        },
        "id": "0MKFfhLSHrIe",
        "outputId": "ac95e888-21e5-45ba-9545-d87644cf4911"
      },
      "source": [
        "data_table = pd.pivot_table(data,values='rating',columns='item_name',index='user_id')\n",
        "data_table"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>item_name</th>\n",
              "      <th>'Til There Was You (1997)</th>\n",
              "      <th>1-900 (1994)</th>\n",
              "      <th>101 Dalmatians (1996)</th>\n",
              "      <th>12 Angry Men (1957)</th>\n",
              "      <th>187 (1997)</th>\n",
              "      <th>2 Days in the Valley (1996)</th>\n",
              "      <th>20,000 Leagues Under the Sea (1954)</th>\n",
              "      <th>2001: A Space Odyssey (1968)</th>\n",
              "      <th>3 Ninjas: High Noon At Mega Mountain (1998)</th>\n",
              "      <th>39 Steps, The (1935)</th>\n",
              "      <th>8 1/2 (1963)</th>\n",
              "      <th>8 Heads in a Duffel Bag (1997)</th>\n",
              "      <th>8 Seconds (1994)</th>\n",
              "      <th>A Chef in Love (1996)</th>\n",
              "      <th>Above the Rim (1994)</th>\n",
              "      <th>Absolute Power (1997)</th>\n",
              "      <th>Abyss, The (1989)</th>\n",
              "      <th>Ace Ventura: Pet Detective (1994)</th>\n",
              "      <th>Ace Ventura: When Nature Calls (1995)</th>\n",
              "      <th>Across the Sea of Time (1995)</th>\n",
              "      <th>Addams Family Values (1993)</th>\n",
              "      <th>Addicted to Love (1997)</th>\n",
              "      <th>Addiction, The (1995)</th>\n",
              "      <th>Adventures of Pinocchio, The (1996)</th>\n",
              "      <th>Adventures of Priscilla, Queen of the Desert, The (1994)</th>\n",
              "      <th>Adventures of Robin Hood, The (1938)</th>\n",
              "      <th>Affair to Remember, An (1957)</th>\n",
              "      <th>African Queen, The (1951)</th>\n",
              "      <th>Afterglow (1997)</th>\n",
              "      <th>Age of Innocence, The (1993)</th>\n",
              "      <th>Aiqing wansui (1994)</th>\n",
              "      <th>Air Bud (1997)</th>\n",
              "      <th>Air Force One (1997)</th>\n",
              "      <th>Air Up There, The (1994)</th>\n",
              "      <th>Airheads (1994)</th>\n",
              "      <th>Akira (1988)</th>\n",
              "      <th>Aladdin (1992)</th>\n",
              "      <th>Aladdin and the King of Thieves (1996)</th>\n",
              "      <th>Alaska (1996)</th>\n",
              "      <th>Albino Alligator (1996)</th>\n",
              "      <th>...</th>\n",
              "      <th>Whole Wide World, The (1996)</th>\n",
              "      <th>Widows' Peak (1994)</th>\n",
              "      <th>Wife, The (1995)</th>\n",
              "      <th>Wild America (1997)</th>\n",
              "      <th>Wild Bill (1995)</th>\n",
              "      <th>Wild Bunch, The (1969)</th>\n",
              "      <th>Wild Reeds (1994)</th>\n",
              "      <th>Wild Things (1998)</th>\n",
              "      <th>William Shakespeare's Romeo and Juliet (1996)</th>\n",
              "      <th>Willy Wonka and the Chocolate Factory (1971)</th>\n",
              "      <th>Window to Paris (1994)</th>\n",
              "      <th>Wings of Courage (1995)</th>\n",
              "      <th>Wings of Desire (1987)</th>\n",
              "      <th>Wings of the Dove, The (1997)</th>\n",
              "      <th>Winnie the Pooh and the Blustery Day (1968)</th>\n",
              "      <th>Winter Guest, The (1997)</th>\n",
              "      <th>Wishmaster (1997)</th>\n",
              "      <th>With Honors (1994)</th>\n",
              "      <th>Withnail and I (1987)</th>\n",
              "      <th>Witness (1985)</th>\n",
              "      <th>Wizard of Oz, The (1939)</th>\n",
              "      <th>Wolf (1994)</th>\n",
              "      <th>Woman in Question, The (1950)</th>\n",
              "      <th>Women, The (1939)</th>\n",
              "      <th>Wonderful, Horrible Life of Leni Riefenstahl, The (1993)</th>\n",
              "      <th>Wonderland (1997)</th>\n",
              "      <th>Wooden Man's Bride, The (Wu Kui) (1994)</th>\n",
              "      <th>World of Apu, The (Apur Sansar) (1959)</th>\n",
              "      <th>Wrong Trousers, The (1993)</th>\n",
              "      <th>Wyatt Earp (1994)</th>\n",
              "      <th>Yankee Zulu (1994)</th>\n",
              "      <th>Year of the Horse (1997)</th>\n",
              "      <th>You So Crazy (1994)</th>\n",
              "      <th>Young Frankenstein (1974)</th>\n",
              "      <th>Young Guns (1988)</th>\n",
              "      <th>Young Guns II (1990)</th>\n",
              "      <th>Young Poisoner's Handbook, The (1995)</th>\n",
              "      <th>Zeus and Roxanne (1997)</th>\n",
              "      <th>unknown</th>\n",
              "      <th>Á köldum klaka (Cold Fever) (1994)</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>939</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>940</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>941</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>942</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>5.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>943</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>943 rows × 1664 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "item_name  'Til There Was You (1997)  ...  Á köldum klaka (Cold Fever) (1994)\n",
              "user_id                               ...                                    \n",
              "1                                NaN  ...                                 NaN\n",
              "2                                NaN  ...                                 NaN\n",
              "3                                NaN  ...                                 NaN\n",
              "4                                NaN  ...                                 NaN\n",
              "5                                NaN  ...                                 NaN\n",
              "...                              ...  ...                                 ...\n",
              "939                              NaN  ...                                 NaN\n",
              "940                              NaN  ...                                 NaN\n",
              "941                              NaN  ...                                 NaN\n",
              "942                              NaN  ...                                 NaN\n",
              "943                              NaN  ...                                 NaN\n",
              "\n",
              "[943 rows x 1664 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ym234PQmIGMS"
      },
      "source": [
        "using the pearson’s correlation coefficient to recommend movies to users based on the movies they liked"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCMCuC52HrLw",
        "outputId": "4630ddcf-1440-41de-d35d-c98c234dd902"
      },
      "source": [
        "print(\"here are a list of 20 movies to recommend to a user who has liked 'Til There Was You (1997)'\")\n",
        "print(df3.corr()[0].sort_values(ascending=False).iloc[:20])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "here are a list of 20 movies to recommend to a user who has liked 'Til There Was You (1997)'\n",
            "0      1.000000\n",
            "58     1.000000\n",
            "134    1.000000\n",
            "148    1.000000\n",
            "981    1.000000\n",
            "258    1.000000\n",
            "482    1.000000\n",
            "317    1.000000\n",
            "59     0.999999\n",
            "563    0.999999\n",
            "212    0.999999\n",
            "175    0.999999\n",
            "511    0.999999\n",
            "191    0.999999\n",
            "285    0.999999\n",
            "660    0.999998\n",
            "602    0.999998\n",
            "831    0.999998\n",
            "855    0.999998\n",
            "749    0.999997\n",
            "Name: 0, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlBqMfJFHrNg",
        "outputId": "1b0b3f1a-643d-42dc-dc94-a65e00215602"
      },
      "source": [
        "print(\"here are a list of 10 movies to recommend to a user who has liked '1-900 (1994)'\")\n",
        "print(df3.corr()[1].sort_values(ascending=False).iloc[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "here are a list of 10 movies to recommend to a user who has liked '1-900 (1994)'\n",
            "1       1.0\n",
            "1225    1.0\n",
            "996     1.0\n",
            "216     1.0\n",
            "213     1.0\n",
            "158     1.0\n",
            "1084    1.0\n",
            "1404    1.0\n",
            "45      1.0\n",
            "50      1.0\n",
            "Name: 1, dtype: float64\n"
          ]
        }
      ]
    }
  ]
}